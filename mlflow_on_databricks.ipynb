{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking experiments on Databricks MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mlflow databricks-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Authentication of Databricks CE\n",
    "\n",
    "### Use the API mlflow.login()\n",
    "\n",
    "* Databricks Host: Use ```https://community.cloud.databricks.com/```\n",
    "* Username: Your email address that signs in Databricks CE: ```datanerd07@gmail.com```\n",
    "* Password: Your password of Databricks CE: ```D4t4br1cks!!```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/23 10:54:01 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://community.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the databricks connection with a test experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/check-databricks-connection\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"foo\", 1)\n",
    "    mlflow.log_metric(\"bar\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Victor's MLmodels experiments in Databricks MLFlow\n",
    "\n",
    "- RandomForestClassifier\n",
    "- KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "def load_data(filename):\n",
    "    script_dir = os.getcwd()\n",
    "    data_path = os.path.join(script_dir, 'data', filename)\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df[df.columns[:-2]]\n",
    "    df = df.drop(['CLIENTNUM'], axis=1)\n",
    "    return df\n",
    "\n",
    "def save_cleaned_data(df):\n",
    "    script_dir = os.path.dirname(__file__)\n",
    "    data_path = os.path.join(script_dir, '..', 'data', 'cleaned_data.csv')\n",
    "    df.to_csv(data_path, index=False)\n",
    "\n",
    "def get_model(X_train, model):\n",
    "    # Identifying categoricals and numericals\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_cols = X_train.select_dtypes(exclude=['object', 'category']).columns\n",
    "\n",
    "    # Numerical preprocessing\n",
    "    numerical_pipeline = make_pipeline(\n",
    "        SimpleImputer(strategy='mean'),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "    # Categorical preprocessing\n",
    "    categorical_pipeline = make_pipeline(\n",
    "        OneHotEncoder(handle_unknown='ignore')\n",
    "    )\n",
    "\n",
    "    # ColumnTransformer \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_pipeline, categorical_cols),\n",
    "            ('num', numerical_pipeline, numerical_cols) \n",
    "        ],\n",
    "    remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # A pipeline that includes the above\n",
    "    pipeline = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def train_model(model_pipe, X_train, y_train):\n",
    "    model_pipe.fit(X_train, y_train)\n",
    "    return model_pipe\n",
    "\n",
    "def evaluate_model(trained_model, X_test, y_test):\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    y_prob = trained_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'classification_report': report,\n",
    "        'y_pred': y_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "RANDOMFORESTCLASSIFIER\n",
      "--------------------\n",
      "train_score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miubuntu/home/BECODE_PROJECTS/9_mlops-project/mlops--project/.venv/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': '[{\"type\": \"long\", \"name\": \"Customer_Age\", \"required\": true}, {\"type\": \"string\", \"name\": \"Gender\", \"required\": true}, {\"type\": \"long\", \"name\": \"Dependent_count\", \"required\": true}, {\"type\": \"string\", \"name\": \"Education_Level\", \"required\": true}, {\"type\": \"string\", \"name\": \"Marital_Status\", \"required\": true}, {\"type\": \"string\", \"name\": \"Income_Category\", \"required\": true}, {\"type\": \"string\", \"name\": \"Card_Category\", \"required\": true}, {\"type\": \"long\", \"name\": \"Months_on_book\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Relationship_Count\", \"required\": true}, {\"type\": \"long\", \"name\": \"Months_Inactive_12_mon\", \"required\": true}, {\"type\": \"long\", \"name\": \"Contacts_Count_12_mon\", \"required\": true}, {\"type\": \"double\", \"name\": \"Credit_Limit\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Revolving_Bal\", \"required\": true}, {\"type\": \"double\", \"name\": \"Avg_Open_To_Buy\", \"required\": true}, {\"type\": \"double\", \"name\": \"Total_Amt_Chng_Q4_Q1\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Trans_Amt\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Trans_Ct\", \"required\": true}, {\"type\": \"double\", \"name\": \"Total_Ct_Chng_Q4_Q1\", \"required\": true}, {\"type\": \"double\", \"name\": \"Avg_Utilization_Ratio\", \"required\": true}]', 'outputs': '[{\"type\": \"string\", \"name\": \"Attrition_Flag\", \"required\": true}]', 'params': '[{\"name\": \"model_type\", \"type\": \"string\", \"default\": \"RandomForest\", \"shape\": null}]'}\n",
      "test_score: 0.96\n",
      "accuracy: 0.955\n",
      "roc_auc: 0.987\n",
      "classification_report:                    precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.88      0.84      0.86       327\n",
      "Existing Customer       0.97      0.98      0.97      1699\n",
      "\n",
      "         accuracy                           0.96      2026\n",
      "        macro avg       0.92      0.91      0.92      2026\n",
      "     weighted avg       0.95      0.96      0.95      2026\n",
      "\n",
      "Mean Test Accuracy: 0.956\n",
      "Mean Train Accuracy: 1.0\n",
      "Mean Fit Time: 1.484\n",
      "Mean Score Time: 0.02\n",
      "--------------------\n",
      "KNEIGHBORSCLASSIFIER\n",
      "--------------------\n",
      "train_score: 0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miubuntu/home/BECODE_PROJECTS/9_mlops-project/mlops--project/.venv/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': '[{\"type\": \"long\", \"name\": \"Customer_Age\", \"required\": true}, {\"type\": \"string\", \"name\": \"Gender\", \"required\": true}, {\"type\": \"long\", \"name\": \"Dependent_count\", \"required\": true}, {\"type\": \"string\", \"name\": \"Education_Level\", \"required\": true}, {\"type\": \"string\", \"name\": \"Marital_Status\", \"required\": true}, {\"type\": \"string\", \"name\": \"Income_Category\", \"required\": true}, {\"type\": \"string\", \"name\": \"Card_Category\", \"required\": true}, {\"type\": \"long\", \"name\": \"Months_on_book\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Relationship_Count\", \"required\": true}, {\"type\": \"long\", \"name\": \"Months_Inactive_12_mon\", \"required\": true}, {\"type\": \"long\", \"name\": \"Contacts_Count_12_mon\", \"required\": true}, {\"type\": \"double\", \"name\": \"Credit_Limit\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Revolving_Bal\", \"required\": true}, {\"type\": \"double\", \"name\": \"Avg_Open_To_Buy\", \"required\": true}, {\"type\": \"double\", \"name\": \"Total_Amt_Chng_Q4_Q1\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Trans_Amt\", \"required\": true}, {\"type\": \"long\", \"name\": \"Total_Trans_Ct\", \"required\": true}, {\"type\": \"double\", \"name\": \"Total_Ct_Chng_Q4_Q1\", \"required\": true}, {\"type\": \"double\", \"name\": \"Avg_Utilization_Ratio\", \"required\": true}]', 'outputs': '[{\"type\": \"string\", \"name\": \"Attrition_Flag\", \"required\": true}]', 'params': '[{\"name\": \"model_type\", \"type\": \"string\", \"default\": \"Kneigbors\", \"shape\": null}]'}\n",
      "test_score: 0.84\n",
      "accuracy: 0.845\n",
      "roc_auc: 0.902\n",
      "classification_report:                    precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.51      0.85      0.64       327\n",
      "Existing Customer       0.97      0.84      0.90      1699\n",
      "\n",
      "         accuracy                           0.84      2026\n",
      "        macro avg       0.74      0.85      0.77      2026\n",
      "     weighted avg       0.89      0.84      0.86      2026\n",
      "\n",
      "Mean Test Accuracy: 0.854\n",
      "Mean Train Accuracy: 0.907\n",
      "Mean Fit Time: 0.037\n",
      "Mean Score Time: 0.036\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlflow.set_experiment(\"/Victor Models Experiment\")\n",
    "\n",
    "# Load and preprocess data\n",
    "filename = 'BankChurners.csv'\n",
    "df = load_data(filename)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "def split_data(df):\n",
    "    \"\"\"\n",
    "    Split the data into train and test sets\n",
    "    \"\"\"\n",
    "    X = df.drop('Attrition_Flag', axis=1)\n",
    "    y = df['Attrition_Flag']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def log_model_and_metrics(trained_model, X_train, y_train, X_test, y_test, evaluation_results, model_type):\n",
    "    \"\"\"\n",
    "    Log the model and metrics. Model signature prints input and output schema of the model\n",
    "    \"\"\"\n",
    "    # Log the model\n",
    "    model_signature = infer_signature(X_train, y_train, params={'model_type': model_type})\n",
    "    print(model_signature.to_dict())\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=trained_model,\n",
    "        artifact_path=\"trained_model\",\n",
    "        conda_env=None,\n",
    "        signature=model_signature\n",
    "        # registered_model_name=\"random_forest_classifier_trained\"\n",
    "    )\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric('accuracy', evaluation_results['accuracy'])\n",
    "    mlflow.log_metric('roc_auc', evaluation_results['roc_auc'])\n",
    "    \n",
    "    with open(\"metrics/classification_report.txt\", \"w\") as f:\n",
    "        f.write(evaluation_results['classification_report'])\n",
    "    mlflow.log_artifact(\"metrics/classification_report.txt\", artifact_path=\"metrics\")\n",
    "\n",
    "def save_and_log_plots(trained_model, X_test, y_test):\n",
    "    \"\"\" Plot the ROC and PR curves\n",
    "    \"\"\"\n",
    "    roc_display = RocCurveDisplay.from_estimator(trained_model, X_test, y_test)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.savefig(\"metrics/roc_curve.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"metrics/roc_curve.png\", artifact_path=\"metric_graphs\")\n",
    "\n",
    "    pr_display = PrecisionRecallDisplay.from_estimator(trained_model, X_test, y_test)\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"metrics/precision_recall_curve.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"metrics/precision_recall_curve.png\", artifact_path=\"metric_graphs\")\n",
    "\n",
    "def cross_validate_model(trained_model, X_train, y_train):\n",
    "    \"\"\" Cross validation\n",
    "    \"\"\"\n",
    "    cv_results = cross_validate(trained_model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    print(\"Mean Test Accuracy:\", round(cv_results['test_score'].mean(), 3))\n",
    "    print(\"Mean Train Accuracy:\", round(cv_results['train_score'].mean(), 3))\n",
    "    print(\"Mean Fit Time:\", round(cv_results['fit_time'].mean(), 3))\n",
    "    print(\"Mean Score Time:\", round(cv_results['score_time'].mean(), 3))\n",
    "\n",
    "# -- Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "def mlflow_experiment_run(run_name, model_name, ml_model, model_type):\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        print('--------------------')\n",
    "        print(model_name)\n",
    "        print('--------------------')\n",
    "        # -- Get the model\n",
    "        model = get_model(X_train,ml_model)\n",
    "        \n",
    "        # -- Train the model\n",
    "        trained_model = train_model(model, X_train, y_train)\n",
    "        train_score = round(trained_model.score(X_train, y_train), 3)\n",
    "\n",
    "        mlflow.log_metric('train_score', train_score)\n",
    "        print(\"train_score:\", train_score)\n",
    "\n",
    "        evaluation_results = evaluate_model(trained_model, X_test, y_test)\n",
    "        log_model_and_metrics(trained_model, X_train, y_train, X_test, y_test, evaluation_results, model_type)\n",
    "\n",
    "        test_score = round(trained_model.score(X_test, y_test), 2)\n",
    "        print(\"test_score:\", test_score)\n",
    "\n",
    "        print(\"accuracy:\", round(evaluation_results['accuracy'], 3))\n",
    "        print(\"roc_auc:\", round(evaluation_results['roc_auc'], 3))\n",
    "        print(\"classification_report:\", evaluation_results['classification_report'])\n",
    "\n",
    "        save_and_log_plots(trained_model, X_test, y_test)\n",
    "        cross_validate_model(trained_model, X_train, y_train)\n",
    "\n",
    "mlflow_experiment_run('RandomForestClassifier', 'RANDOMFORESTCLASSIFIER', RandomForestClassifier(), 'RandomForest')\n",
    "mlflow_experiment_run('KNeighborsClassifier', 'KNEIGHBORSCLASSIFIER', KNeighborsClassifier(), 'Kneigbors')\n",
    "mlflow_experiment_run('GradientBoostClassifier', 'GRADIENTBOOSTCLASSIFIER', GradientBoostingClassifier(), 'GradientBoost')\n",
    "mlflow_experiment_run('DecisionTreeClassifier', 'DECISIONTREECLASSIFIER', DecisionTreeClassifier(), 'DecisionTree')\n",
    "mlflow_experiment_run('AdaBoostClassifier', 'ADABOOSTCLASSIFIER', AdaBoostClassifier(), 'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
